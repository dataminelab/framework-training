AWS:
# Instance types: http://aws.amazon.com/ec2/instance-types/
# Check spot prices: Amazon EC2 console, click Spot Requests.
# Current spot prices: https://aws.amazon.com/ec2/purchasing-options/spot-instances/
# http://ec2price.com/?product=Linux/UNIX&type=m1.medium&region=us-east-1&window=60
# Compare to normal prices: http://aws.amazon.com/ec2/pricing/

AWS steps:
# Read access and secret keys (see “Security Credentials” on account page)
# Go to: https://console.aws.amazon.com/ec2/home
# Click on Key Pairs
# Create ssh key/pair: https://docs.aws.amazon.com/ElasticMapReduce/latest/DeveloperGuide/emr-plan-access-ssh.html
# Create S3 bucket, it will be created automatically though
# Elastic Map Reduce -> create cluster
# Add HBase in "Applications to be installed"
# Request spot instances
# Choose EC2 availability zone according to spot prices

# When connecting through SSH

# Run analysis and check the output
https://hadoop.apache.org/docs/r1.2.1/file_system_shell.html

# Useful for downloading all results
hadoop dfs -getmerge /user/training/words-output-2/ ./parts.txt



