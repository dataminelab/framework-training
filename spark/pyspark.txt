
# First start with spark.txt

# Start pyspark

pyspark

words = sc.textFile('s3://radek-training/hamlet.txt').cache()

wordcounts = words.map( lambda x: x.replace(',',' ').replace('.',' ').replace('-',' ').lower()) \
        .flatMap(lambda x: x.split()) \
        .map(lambda x: (x, 1)) \
        .reduceByKey(lambda x,y:x+y) \
        .map(lambda x:(x[1],x[0])) \
        .sortByKey(False) 
wordcounts.take(10)

numAs = words.filter(lambda s: 'Hamlet' in s).count()
numBs = words.filter(lambda s: 'King' in s).count()

print("Lines with Hamlet: %i, lines with King: %i" % (numAs, numBs))

# Submit SimpleApp.py

checkout the code
```
sudo yum install -y git
git clone https://github.com/dataminelab/framework-training.git
cd framework-training/spark/
```

spark-submit --master local[4] SimpleApp.py

# To submit this on yarn-cluster

aws s3 cp ./SimpleApp.py s3://radek-training/

spark-submit --verbose --deploy-mode cluster --master yarn-cluster --num-executors 2 --executor-memory 1g s3://radek-training/SimpleApp.py

# PySpark and SQL

spark-submit --master local[4] SparkSql.py

or submit it to yarn-client

spark-submit --master yarn-client ./SparkSql.py

or spark cluster

aws s3 cp ./SparkSql.py s3://radek-training/

spark-submit --verbose --deploy-mode cluster --master yarn-cluster --num-executors 2 --executor-memory 1g s3://radek-training/SparkSql.py


