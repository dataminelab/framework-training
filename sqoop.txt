## Sqoop

# installation
wget http://apache.mirror.anlx.net/sqoop/1.4.6/sqoop-1.4.6.bin__hadoop-2.0.4-alpha.tar.gz

tar zxvf ./sqoop-1.4.6.bin__hadoop-2.0.4-alpha.tar.gz

sudo mv ./sqoop-1.4.6.bin__hadoop-2.0.4-alpha/ /usr/lib/sqoop
export PATH=$PATH:/usr/lib/sqoop/bin/


# Download MySQL JDBC driver
wget http://dev.mysql.com/get/Downloads/Connector-J/mysql-connector-java-5.1.30.tar.gz
tar xzvf ./mysql-connector-java-5.1.30.tar.gz
cp mysql-connector-java-5.1.30/mysql-connector-java-5.1.30-bin.jar /usr/lib/sqoop/lib/


# Let's import sample MySQL data first
# Who've heard about Enron?
# https://www.youtube.com/watch?v=1dNZaKLjYbc
# Forensic public database: 250k messages, 1.5M receipients

see: http://opendata.stackexchange.com/questions/3802/enron-email-dataset-in-mysql
wget http://www.ahschulz.de/pub/R/data/enron-mysqldump_v5.sql.gz

gzip -d enron-mysqldump_v5.sql.gz


mysql -u root -e 'create database enron'

# import data
mysql -u root enron < ./enron-mysqldump_v5.sql


# create new table with the data we are interested in
mysql -u root enron
grant all on enron.* to 'enron'@'%' identified by 'enr0n';
grant all on enron.* to 'enron'@localhost identified by 'enr0n';

# just for this experiment (not recommended overall)
# this is required so the sqoop can connect to mysql
sudo vi /etc/my.cnf
bind-address = 0.0.0.0
sudo service mysqld restart

# test it
mysql -u enron -h 127.0.0.1 enron -p

# import this data into HDFS using Sqoop

# Delete folder when reimporting data
# hadoop dfs -rmr /user/hadoop/message

# note, use private DNS IP (see aws EC2 console)

sqoop import --connect jdbc:mysql://ip-10-239-6-83.ec2.internal:3306/enron --username enron --table message --direct --password "enr0n" --fields-terminated-by='\t'

# create Hive table

hive

create external table enron_messages (
  mid int,
  sender string,
  date_time timestamp,
  message_id string,
  subject string,
  body string,
  folder string
)
ROW FORMAT DELIMITED FIELDS TERMINATED BY '\t'
location '/user/hadoop/message';

select * from enron_messages limit 5;

select * from enron_messages where body like "%keyword%" limit 10;


### Avro

CREATE EXTERNAL TABLE avro_enron_messages
ROW FORMAT SERDE 'org.apache.hadoop.hive.serde2.avro.AvroSerDe'
WITH SERDEPROPERTIES (
    'avro.schema.literal' = '{
        "type": "record",
        "name": "EnronMessages",
        "namespace": "com.example.avro",
        "fields": [
            { "name":"mid",  "type":"int"},
            { "name":"sender",  "type":["null","string"]},
            { "name":"date",     "type":["null","string"]},
            { "name":"message_id", "type":["null","string"]},
            { "name":"subject", "type":["null","string"]},
            { "name":"body", "type":["null","string"]},
            { "name":"folder", "type":["null","string"]}
        ]
    }'
)
STORED AS
INPUTFORMAT  'org.apache.hadoop.hive.ql.io.avro.AvroContainerInputFormat'
OUTPUTFORMAT 'org.apache.hadoop.hive.ql.io.avro.AvroContainerOutputFormat'
LOCATION '/user/hadoop/avro/enron_messages';

insert overwrite table avro_enron_messages select * from enron_messages;





